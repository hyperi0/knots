{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn list of lists of equivalent braids with corresponding answers into trainable data\n",
    "\n",
    "def parse_equivalent_braids(allBraids, answers, maxCrossings):\n",
    "\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "\n",
    "    for equivalentBraids, answer in zip(allBraids, answers):\n",
    "        for braid in tf.keras.preprocessing.sequence.pad_sequences(\n",
    "            equivalentBraids, padding=\"post\", maxlen=maxCrossings):\n",
    "            x_data.append(braid)\n",
    "            y_data.append(answer)\n",
    "        \n",
    "    return np.asarray(x_data), np.asarray(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read pre-parsed knot data with braid words and equivalent braids\n",
    "\n",
    "knot_data = pd.read_csv('../data/knot_volume.csv')\n",
    "knot_data[\"Equivalent Braids\"] = knot_data[\"Equivalent Braids\"].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq = knot_data[\"Equivalent Braids\"]\n",
    "\n",
    "maxCrossings = max([max([len(braid) for braid in braids]) for braids in eq])\n",
    "maxStrands = max([max([max([abs(b) for b in braid]) for braid in braids]) for braids in eq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset for training\n",
    "\n",
    "train_split = .8\n",
    "\n",
    "train_data = knot_data.sample(frac=train_split)\n",
    "test_data = knot_data.drop(train_data.index)\n",
    "\n",
    "x_train, y_train = parse_equivalent_braids(train_data[\"Equivalent Braids\"],\n",
    "                    train_data[\"Volume\"], maxCrossings)\n",
    "\n",
    "x_train = tf.keras.utils.to_categorical(x_train, num_classes=maxStrands*2+1)\n",
    "\n",
    "x_test, y_test = parse_equivalent_braids(test_data[\"Equivalent Braids\"],\n",
    "                    test_data[\"Volume\"], maxCrossings)\n",
    "\n",
    "x_test = tf.keras.utils.to_categorical(x_test, num_classes=maxStrands*2+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model from functional api\n",
    "\n",
    "inputs = keras.Input(shape=(maxCrossings, maxStrands*2+1))\n",
    "\n",
    "x = layers.Flatten()(inputs)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "\n",
    "outputs = layers.Dense(1)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=inputs, outputs=outputs, \n",
    "    name=\"quasipositivity_functional\")\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"quasipositivity_functional\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 19, 13)]          0         \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 247)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 64)                15872     \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,097\n",
      "Trainable params: 20,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1189/1189 [==============================] - 1s 539us/step - loss: 16.1262 - mean_squared_error: 16.1262\n",
      "Epoch 2/5\n",
      "1189/1189 [==============================] - 1s 524us/step - loss: 9.2984 - mean_squared_error: 9.2984\n",
      "Epoch 3/5\n",
      "1189/1189 [==============================] - 1s 523us/step - loss: 8.1201 - mean_squared_error: 8.1201\n",
      "Epoch 4/5\n",
      "1189/1189 [==============================] - 1s 517us/step - loss: 7.6488 - mean_squared_error: 7.6488\n",
      "Epoch 5/5\n",
      "1189/1189 [==============================] - 1s 513us/step - loss: 7.3550 - mean_squared_error: 7.3550\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "595/595 [==============================] - 0s 332us/step - loss: 8.3392 - mean_squared_error: 8.3392\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8.33924388885498, 8.33924388885498]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_volume(braid_word):\n",
    "    padded_braid = np.pad(braid_word, (0, maxCrossings - len(braid_word)))\n",
    "    encoded_braid = tf.keras.utils.to_categorical(padded_braid, num_classes=maxStrands*2+1)\n",
    "    return np.asarray(model(np.array([encoded_braid])))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.821954"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "predict_volume([1, -2, 1, 2, 3, -2, 3, -4, 2, -4, -3, 2, -3, 4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c440bc12ae7b4c02b013e707ab2c471f2eefe1e8fcb648aca50990e658b180b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
